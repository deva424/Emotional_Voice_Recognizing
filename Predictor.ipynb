{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPednzzHpF22q6X+i6lA62R"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h_u2t62b9Vnf","executionInfo":{"status":"ok","timestamp":1757412726257,"user_tz":-330,"elapsed":26148,"user":{"displayName":"DEVAMANI","userId":"00230464672143190370"}},"outputId":"ab190db8-cea0-46d5-e2a1-8f2f24903b24"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xMeIPwyf8601","executionInfo":{"status":"ok","timestamp":1757413164464,"user_tz":-330,"elapsed":289,"user":{"displayName":"DEVAMANI","userId":"00230464672143190370"}},"outputId":"f0e1fda2-b460-471b-f178-480ed912199d"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]}],"source":["import numpy as np\n","from tensorflow.keras.models import load_model\n","from sklearn.preprocessing import LabelEncoder\n","import librosa\n","\n","# --- 1. Load the Trained Model ---\n","# Make sure this path is correct\n","model_path = '/content/drive/MyDrive/Emotion Recognition from Speech/emotion_recognition_model.h5'\n","loaded_model = load_model(model_path)\n"]},{"cell_type":"code","source":["\n","# --- 2. Re-create the LabelEncoder ---\n","# You need to define the class names in the correct order as they were during training.\n","# This order is based on the RAVDESS dataset emotion_mapping.\n","class_names = ['angry', 'calm', 'disgust', 'fearful', 'happy', 'neutral', 'sad', 'surprised']\n","label_encoder = LabelEncoder()\n","label_encoder.fit(class_names)\n","\n","# --- 3. Preprocess Your Sample Data ---\n","# Re-use the feature extraction function\n","def extract_features(audio_path, mfcc=True, chroma=True, mel=True):\n","    try:\n","        y, sr = librosa.load(audio_path, sr=None)\n","        features = []\n","        if mfcc:\n","            mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n","            features.append(mfccs)\n","        if chroma:\n","            chroma = np.mean(librosa.feature.chroma_stft(y=y, sr=sr).T, axis=0)\n","            features.append(chroma)\n","        if mel:\n","            mel_spec = np.mean(librosa.feature.melspectrogram(y=y, sr=sr).T, axis=0)\n","            features.append(mel_spec)\n","        return np.hstack(features)\n","    except Exception as e:\n","        print(f\"Error processing {audio_path}: {e}\")\n","        return None\n","\n"],"metadata":{"id":"Pse2roCz-Y0x","executionInfo":{"status":"ok","timestamp":1757413228400,"user_tz":-330,"elapsed":26,"user":{"displayName":"DEVAMANI","userId":"00230464672143190370"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Path to your new audio file. Update this path.\n","sample_audio_path = '/content/drive/MyDrive/Emotion Recognition from Speech/Sample_data/-128-ytshorts.savetube.me.wav'\n","features = extract_features(sample_audio_path)\n","\n","# Reshape for the model\n","if features is not None:\n","    features_reshaped = np.expand_dims(features, axis=0)\n","    features_reshaped = np.expand_dims(features_reshaped, axis=2)\n","\n","    # --- 4. Make a Prediction and Interpret the Results ---\n","    prediction = loaded_model.predict(features_reshaped)\n","\n","    predicted_class_index = np.argmax(prediction)\n","    predicted_emotion = label_encoder.classes_[predicted_class_index]\n","    confidence = np.max(prediction) * 100\n","\n","    print(f\"The predicted emotion is: {predicted_emotion}\")\n","    print(f\"Confidence: {confidence:.2f}%\")\n","else:\n","    print(\"Feature extraction failed, cannot make a prediction.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IaI_7IUB_ZfV","executionInfo":{"status":"ok","timestamp":1757414416656,"user_tz":-330,"elapsed":633,"user":{"displayName":"DEVAMANI","userId":"00230464672143190370"}},"outputId":"50954477-fc88-4440-f53e-88d68b72ece7"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n","The predicted emotion is: fearful\n","Confidence: 100.00%\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"mATZcw77_c2Q"},"execution_count":null,"outputs":[]}]}